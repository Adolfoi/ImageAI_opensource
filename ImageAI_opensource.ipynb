{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Adolfoi/ImageAI_opensource/blob/main/ImageAI_opensource.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d0lVAvnJkTsx",
        "outputId": "2ff1596c-26af-4177-deba-99bd9c6d9c35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
            "Collecting torch==2.0.0+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torch-2.0.0%2Bcu118-cp310-cp310-linux_x86_64.whl (2267.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 GB\u001b[0m \u001b[31m969.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.15.1+cu118\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchvision-0.15.1%2Bcu118-cp310-cp310-linux_x86_64.whl (6.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.1/6.1 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torchtext in /usr/local/lib/python3.10/dist-packages (0.15.2)\n",
            "Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.0.2+cu118)\n",
            "Collecting torchdata==0.6.0\n",
            "  Downloading https://download.pytorch.org/whl/torchdata-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (3.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (3.1.2)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch==2.0.0+cu118) (2.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1+cu118) (1.23.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1+cu118) (2.31.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision==0.15.1+cu118) (9.4.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.10/dist-packages (from torchdata==0.6.0) (2.0.4)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0+cu118) (3.27.4.1)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch==2.0.0+cu118) (16.0.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torchtext) (4.66.1)\n",
            "INFO: pip is looking at multiple versions of torchtext to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchtext\n",
            "  Downloading https://download.pytorch.org/whl/torchtext-0.15.2%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m87.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading https://download.pytorch.org/whl/torchtext-0.15.1%2Bcpu-cp310-cp310-linux_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting torchaudio\n",
            "  Downloading https://download.pytorch.org/whl/cu118/torchaudio-2.0.1%2Bcu118-cp310-cp310-linux_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m90.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch==2.0.0+cu118) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1+cu118) (3.2.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1+cu118) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision==0.15.1+cu118) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch==2.0.0+cu118) (1.3.0)\n",
            "Installing collected packages: torch, torchdata, torchvision, torchtext, torchaudio\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.0.1+cu118\n",
            "    Uninstalling torch-2.0.1+cu118:\n",
            "      Successfully uninstalled torch-2.0.1+cu118\n",
            "  Attempting uninstall: torchdata\n",
            "    Found existing installation: torchdata 0.6.1\n",
            "    Uninstalling torchdata-0.6.1:\n",
            "      Successfully uninstalled torchdata-0.6.1\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.15.2+cu118\n",
            "    Uninstalling torchvision-0.15.2+cu118:\n",
            "      Successfully uninstalled torchvision-0.15.2+cu118\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.15.2\n",
            "    Uninstalling torchtext-0.15.2:\n",
            "      Successfully uninstalled torchtext-0.15.2\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.0.2+cu118\n",
            "    Uninstalling torchaudio-2.0.2+cu118:\n",
            "      Successfully uninstalled torchaudio-2.0.2+cu118\n",
            "Successfully installed torch-2.0.0+cu118 torchaudio-2.0.1+cu118 torchdata-0.6.0 torchtext-0.15.1+cpu torchvision-0.15.1+cu118\n"
          ]
        }
      ],
      "source": [
        "#ライブラリインポート\n",
        "%pip install torch==2.0.0+cu118 torchvision==0.15.1+cu118 torchtext torchaudio torchdata==0.6.0 --index-url https://download.pytorch.org/whl/cu118"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#webUIの本体ダウンロード\n",
        "!git clone https://github.com/AUTOMATIC1111/stable-diffusion-webui"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEc5OFQVR6s4",
        "outputId": "42be1dfb-6c08-4525-8ae4-c25b1f47c0e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'stable-diffusion-webui'...\n",
            "remote: Enumerating objects: 27343, done.\u001b[K\n",
            "remote: Total 27343 (delta 0), reused 0 (delta 0), pack-reused 27343\u001b[K\n",
            "Receiving objects: 100% (27343/27343), 32.19 MiB | 23.70 MiB/s, done.\n",
            "Resolving deltas: 100% (19162/19162), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#プラグインの格納場所へ移動\n",
        "%cd /content/ImageAI/extensions\n",
        "\n",
        "#controlnetプラグインインストール\n",
        "!git clone https://github.com/Mikubill/sd-webui-controlnet"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xqfoD2tE2gs",
        "outputId": "911bb80e-682d-4c98-a81d-e80d4060a54c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: '/content/ImageAI/extensions'\n",
            "/content\n",
            "Cloning into 'sd-webui-controlnet'...\n",
            "remote: Enumerating objects: 7965, done.\u001b[K\n",
            "remote: Counting objects: 100% (2731/2731), done.\u001b[K\n",
            "remote: Compressing objects: 100% (425/425), done.\u001b[K\n",
            "remote: Total 7965 (delta 2435), reused 2441 (delta 2297), pack-reused 5234\u001b[K\n",
            "Receiving objects: 100% (7965/7965), 16.30 MiB | 12.69 MiB/s, done.\n",
            "Resolving deltas: 100% (4654/4654), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#生成モデルのインストール（自分で使うモデルをインストールして下さい）\n",
        "#/content/stable-diffusion-webui/models/Stable-diffusion/に置く\n",
        "\n",
        "!wget https://huggingface.co/nuigurumi/basil_mix/resolve/main/Basil_mix_fixed.safetensors -O /content/stable-diffusion-webui/models/Stable-diffusion/Basil_mix_fixed.safetensors\n",
        "!wget https://huggingface.co/BanKaiPls/AsianModel/resolve/main/BraV4.safetensors -O /content/stable-diffusion-webui/models/Stable-diffusion/BraV4.safetensors\n",
        "!wget https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors -O /content/stable-diffusion-webui/models/VAE/vae-ft-mse-840000-ema-pruned.safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_zB349uR_4Z",
        "outputId": "af55cac3-3817-497b-d286-62d6f2475d54"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-16 09:21:54--  https://huggingface.co/nuigurumi/basil_mix/resolve/main/Basil_mix_fixed.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.80, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/5b/ec/5bec02f48cde4dc46a4a3590ccf377e5b59a146f5f769f4291923392aaa8315a/0ff127093f5be455057742c40cef578407b6933f240ee8dc5ed0f3061196fb38?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27Basil_mix_fixed.safetensors%3B+filename%3D%22Basil_mix_fixed.safetensors%22%3B&Expires=1695115314&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NTExNTMxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy81Yi9lYy81YmVjMDJmNDhjZGU0ZGM0NmE0YTM1OTBjY2YzNzdlNWI1OWExNDZmNWY3NjlmNDI5MTkyMzM5MmFhYTgzMTVhLzBmZjEyNzA5M2Y1YmU0NTUwNTc3NDJjNDBjZWY1Nzg0MDdiNjkzM2YyNDBlZThkYzVlZDBmMzA2MTE5NmZiMzg%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=vrJT3ItODu2cDal4oYlcQbCR1-eiYTaV4Qs6A%7EnM7rTrzV6XXkSnUpRYk-YGePFf41DGAI91r-FO6TVMEiav7rVpCyPeEdfvA4aMy2ApDqFeu14VCXRVHBQSej0X8KkByMjbyI2aLI07HDkmhu25-OnCFaMjR6Y6xLBJfHtludbjISxmI8EPInM8Dpr-obcaBlQDzR--wqYErRAuBtXIiVErpldHJtStnDBgG%7EHhEs43GblZgF5NAHL-1cwaOPWtrkPOj6kP668iIbrgNSV0XL78UY4y0oF1a9nqsrrRMupFFPGBrS6yQhA624MpAGnLX4YHgAefV0zkE6aFtzewfA__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-09-16 09:21:54--  https://cdn-lfs.huggingface.co/repos/5b/ec/5bec02f48cde4dc46a4a3590ccf377e5b59a146f5f769f4291923392aaa8315a/0ff127093f5be455057742c40cef578407b6933f240ee8dc5ed0f3061196fb38?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27Basil_mix_fixed.safetensors%3B+filename%3D%22Basil_mix_fixed.safetensors%22%3B&Expires=1695115314&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NTExNTMxNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy81Yi9lYy81YmVjMDJmNDhjZGU0ZGM0NmE0YTM1OTBjY2YzNzdlNWI1OWExNDZmNWY3NjlmNDI5MTkyMzM5MmFhYTgzMTVhLzBmZjEyNzA5M2Y1YmU0NTUwNTc3NDJjNDBjZWY1Nzg0MDdiNjkzM2YyNDBlZThkYzVlZDBmMzA2MTE5NmZiMzg%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=vrJT3ItODu2cDal4oYlcQbCR1-eiYTaV4Qs6A%7EnM7rTrzV6XXkSnUpRYk-YGePFf41DGAI91r-FO6TVMEiav7rVpCyPeEdfvA4aMy2ApDqFeu14VCXRVHBQSej0X8KkByMjbyI2aLI07HDkmhu25-OnCFaMjR6Y6xLBJfHtludbjISxmI8EPInM8Dpr-obcaBlQDzR--wqYErRAuBtXIiVErpldHJtStnDBgG%7EHhEs43GblZgF5NAHL-1cwaOPWtrkPOj6kP668iIbrgNSV0XL78UY4y0oF1a9nqsrrRMupFFPGBrS6yQhA624MpAGnLX4YHgAefV0zkE6aFtzewfA__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.239.18.29, 18.239.18.84, 18.239.18.94, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.239.18.29|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2132625431 (2.0G) [binary/octet-stream]\n",
            "Saving to: ‘/content/stable-diffusion-webui/models/Stable-diffusion/Basil_mix_fixed.safetensors’\n",
            "\n",
            "/content/stable-dif 100%[===================>]   1.99G  37.8MB/s    in 53s     \n",
            "\n",
            "2023-09-16 09:22:48 (38.1 MB/s) - ‘/content/stable-diffusion-webui/models/Stable-diffusion/Basil_mix_fixed.safetensors’ saved [2132625431/2132625431]\n",
            "\n",
            "--2023-09-16 09:22:48--  https://huggingface.co/BanKaiPls/AsianModel/resolve/main/BraV4.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.32.121.112, 13.32.121.124, 13.32.121.4, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.32.121.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2023-09-16 09:22:48 ERROR 404: Not Found.\n",
            "\n",
            "--2023-09-16 09:22:48--  https://huggingface.co/stabilityai/sd-vae-ft-mse-original/resolve/main/vae-ft-mse-840000-ema-pruned.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.32.121.112, 13.32.121.124, 13.32.121.4, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.32.121.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/ec/ee/eceee26c5834d8a75cf04eeb17dfc06d1d5fe1d80c2f19520b148c11e2e98c45/735e4c3a447a3255760d7f86845f09f937809baa529c17370d83e4c3758f3c75?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27vae-ft-mse-840000-ema-pruned.safetensors%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.safetensors%22%3B&Expires=1695113251&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NTExMzI1MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy9lZS9lY2VlZTI2YzU4MzRkOGE3NWNmMDRlZWIxN2RmYzA2ZDFkNWZlMWQ4MGMyZjE5NTIwYjE0OGMxMWUyZTk4YzQ1LzczNWU0YzNhNDQ3YTMyNTU3NjBkN2Y4Njg0NWYwOWY5Mzc4MDliYWE1MjljMTczNzBkODNlNGMzNzU4ZjNjNzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=p3Wxv3wOsMro3u8xNCmIwcxcv5IxomSPYgqyGhbrg5Lm-6HtTZ5bCmSXwXD5N4CjCC9wkGRWmM0xlWhjjJ7h8dpAd4L8x8fG7wzWhHvQGLFYa4viuv2o66%7E9MKg0aMjZou1z8c251WFwcbef6xqPYFuuTv-l2cnak8RptBwnMiI%7Es38eqSNM4D6vBA82lF33j1raVeqEv-2drLtbNhy-Vn1UsmWIlWqWrFFVtDrt0VP%7ExTMZnmvxeJBwchm9vbbAARsMKtyxIg6wAVU-hXgzpLgJIors%7EjCbPqWO9zzrSp4A4ktobWpt5Q6QdmcqENgKPt1Pa6h%7ErsAQsYP8NSGR7Q__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-09-16 09:22:49--  https://cdn-lfs.huggingface.co/repos/ec/ee/eceee26c5834d8a75cf04eeb17dfc06d1d5fe1d80c2f19520b148c11e2e98c45/735e4c3a447a3255760d7f86845f09f937809baa529c17370d83e4c3758f3c75?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27vae-ft-mse-840000-ema-pruned.safetensors%3B+filename%3D%22vae-ft-mse-840000-ema-pruned.safetensors%22%3B&Expires=1695113251&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NTExMzI1MX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9lYy9lZS9lY2VlZTI2YzU4MzRkOGE3NWNmMDRlZWIxN2RmYzA2ZDFkNWZlMWQ4MGMyZjE5NTIwYjE0OGMxMWUyZTk4YzQ1LzczNWU0YzNhNDQ3YTMyNTU3NjBkN2Y4Njg0NWYwOWY5Mzc4MDliYWE1MjljMTczNzBkODNlNGMzNzU4ZjNjNzU%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=p3Wxv3wOsMro3u8xNCmIwcxcv5IxomSPYgqyGhbrg5Lm-6HtTZ5bCmSXwXD5N4CjCC9wkGRWmM0xlWhjjJ7h8dpAd4L8x8fG7wzWhHvQGLFYa4viuv2o66%7E9MKg0aMjZou1z8c251WFwcbef6xqPYFuuTv-l2cnak8RptBwnMiI%7Es38eqSNM4D6vBA82lF33j1raVeqEv-2drLtbNhy-Vn1UsmWIlWqWrFFVtDrt0VP%7ExTMZnmvxeJBwchm9vbbAARsMKtyxIg6wAVU-hXgzpLgJIors%7EjCbPqWO9zzrSp4A4ktobWpt5Q6QdmcqENgKPt1Pa6h%7ErsAQsYP8NSGR7Q__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.239.18.29, 18.239.18.84, 18.239.18.68, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.239.18.29|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 334641190 (319M) [binary/octet-stream]\n",
            "Saving to: ‘/content/stable-diffusion-webui/models/VAE/vae-ft-mse-840000-ema-pruned.safetensors’\n",
            "\n",
            "/content/stable-dif 100%[===================>] 319.14M   503MB/s    in 0.6s    \n",
            "\n",
            "2023-09-16 09:22:49 (503 MB/s) - ‘/content/stable-diffusion-webui/models/VAE/vae-ft-mse-840000-ema-pruned.safetensors’ saved [334641190/334641190]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#controlnetモデルのダウンロード\n",
        "!wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_canny-fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_canny-fp16.safetensors\n",
        "!wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_depth-fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_depth-fp16.safetensors\n",
        "!wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_hed-fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_hed-fp16.safetensors\n",
        "!wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_mlsd-fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_mlsd-fp16.safetensors\n",
        "!wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_normal-fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_normal-fp16.safetensors\n",
        "!wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_openpose-fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_openpose-fp16.safetensors\n",
        "!wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_scribble-fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_scribble-fp16.safetensors\n",
        "!wget https://huggingface.co/webui/ControlNet-modules-safetensors/resolve/main/control_seg-fp16.safetensors -O /content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_seg-fp16.safetensors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbcEkhaqSGIZ",
        "outputId": "2bf8a936-7936-4612-a70c-56249de70549"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_canny-fp16.safetensors: No such file or directory\n",
            "/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_depth-fp16.safetensors: No such file or directory\n",
            "/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_hed-fp16.safetensors: No such file or directory\n",
            "/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_mlsd-fp16.safetensors: No such file or directory\n",
            "/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_normal-fp16.safetensors: No such file or directory\n",
            "/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_openpose-fp16.safetensors: No such file or directory\n",
            "/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_scribble-fp16.safetensors: No such file or directory\n",
            "/content/stable-diffusion-webui/extensions/sd-webui-controlnet/models/control_seg-fp16.safetensors: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#webUI本体へ移動\n",
        "%cd /content/stable-diffusion-webui\n",
        "\n",
        "!python launch.py --share --xformers --enable-insecure-extension-access"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i8-LqdX4SJq7",
        "outputId": "b0e87ca8-48bb-4d37-f51b-3b9e53199206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/stable-diffusion-webui\n",
            "Python 3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "Version: v1.6.0\n",
            "Commit hash: 5ef669de080814067961f28357256e8fe27544f4\n",
            "Installing clip\n",
            "Installing open_clip\n",
            "Installing xformers\n",
            "Cloning Stable Diffusion into /content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai'...\n",
            "remote: Enumerating objects: 574, done.\u001b[K\n",
            "remote: Counting objects: 100% (328/328), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 574 (delta 252), reused 223 (delta 223), pack-reused 246\u001b[K\n",
            "Receiving objects: 100% (574/574), 73.44 MiB | 25.66 MiB/s, done.\n",
            "Resolving deltas: 100% (273/273), done.\n",
            "Cloning Stable Diffusion XL into /content/stable-diffusion-webui/repositories/generative-models...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/generative-models'...\n",
            "remote: Enumerating objects: 740, done.\u001b[K\n",
            "remote: Counting objects: 100% (563/563), done.\u001b[K\n",
            "remote: Compressing objects: 100% (283/283), done.\u001b[K\n",
            "remote: Total 740 (delta 340), reused 425 (delta 266), pack-reused 177\u001b[K\n",
            "Receiving objects: 100% (740/740), 22.31 MiB | 22.53 MiB/s, done.\n",
            "Resolving deltas: 100% (378/378), done.\n",
            "Cloning K-diffusion into /content/stable-diffusion-webui/repositories/k-diffusion...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/k-diffusion'...\n",
            "remote: Enumerating objects: 1047, done.\u001b[K\n",
            "remote: Counting objects: 100% (323/323), done.\u001b[K\n",
            "remote: Compressing objects: 100% (187/187), done.\u001b[K\n",
            "remote: Total 1047 (delta 218), reused 234 (delta 136), pack-reused 724\u001b[K\n",
            "Receiving objects: 100% (1047/1047), 225.32 KiB | 8.05 MiB/s, done.\n",
            "Resolving deltas: 100% (696/696), done.\n",
            "Cloning CodeFormer into /content/stable-diffusion-webui/repositories/CodeFormer...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/CodeFormer'...\n",
            "remote: Enumerating objects: 594, done.\u001b[K\n",
            "remote: Counting objects: 100% (245/245), done.\u001b[K\n",
            "remote: Compressing objects: 100% (89/89), done.\u001b[K\n",
            "remote: Total 594 (delta 176), reused 170 (delta 156), pack-reused 349\u001b[K\n",
            "Receiving objects: 100% (594/594), 17.30 MiB | 15.24 MiB/s, done.\n",
            "Resolving deltas: 100% (287/287), done.\n",
            "Cloning BLIP into /content/stable-diffusion-webui/repositories/BLIP...\n",
            "Cloning into '/content/stable-diffusion-webui/repositories/BLIP'...\n",
            "remote: Enumerating objects: 277, done.\u001b[K\n",
            "remote: Counting objects: 100% (165/165), done.\u001b[K\n",
            "remote: Compressing objects: 100% (30/30), done.\u001b[K\n",
            "remote: Total 277 (delta 137), reused 136 (delta 135), pack-reused 112\u001b[K\n",
            "Receiving objects: 100% (277/277), 7.03 MiB | 19.26 MiB/s, done.\n",
            "Resolving deltas: 100% (153/153), done.\n",
            "Installing requirements for CodeFormer\n",
            "Installing requirements\n",
            "Launching Web UI with arguments: --share --xformers --enable-insecure-extension-access\n",
            "2023-09-16 09:24:10.515769: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "reading metadata for /content/stable-diffusion-webui/models/Stable-diffusion/BraV4.safetensors: AssertionError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 74, in __init__\n",
            "    self.metadata = cache.cached_data_for_file('safetensors-metadata', \"checkpoint/\" + name, filename, read_metadata)\n",
            "  File \"/content/stable-diffusion-webui/modules/cache.py\", line 115, in cached_data_for_file\n",
            "    value = func()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 66, in read_metadata\n",
            "    metadata = read_metadata_from_safetensors(filename)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 269, in read_metadata_from_safetensors\n",
            "    assert metadata_len > 2 and json_start in (b'{\"', b\"{'\"), f\"{filename} is not a safetensors file\"\n",
            "AssertionError: /content/stable-diffusion-webui/models/Stable-diffusion/BraV4.safetensors is not a safetensors file\n",
            "\n",
            "Calculating sha256 for /content/stable-diffusion-webui/models/Stable-diffusion/Basil_mix_fixed.safetensors: Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://3c5fb0b72f078a2292.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "Startup time: 91.6s (prepare environment: 74.2s, import torch: 7.1s, import gradio: 1.2s, setup paths: 2.3s, initialize shared: 0.3s, other imports: 1.4s, setup codeformer: 0.3s, load scripts: 1.4s, create ui: 0.5s, gradio launch: 3.1s).\n",
            "0ff127093f5be455057742c40cef578407b6933f240ee8dc5ed0f3061196fb38\n",
            "Loading weights [0ff127093f] from /content/stable-diffusion-webui/models/Stable-diffusion/Basil_mix_fixed.safetensors\n",
            "Creating model from config: /content/stable-diffusion-webui/configs/v1-inference.yaml\n",
            "Downloading (…)olve/main/vocab.json: 100% 961k/961k [00:00<00:00, 17.3MB/s]\n",
            "Downloading (…)olve/main/merges.txt: 100% 525k/525k [00:00<00:00, 2.11MB/s]\n",
            "Downloading (…)cial_tokens_map.json: 100% 389/389 [00:00<00:00, 2.31MB/s]\n",
            "Downloading (…)okenizer_config.json: 100% 905/905 [00:00<00:00, 5.32MB/s]\n",
            "Downloading (…)lve/main/config.json: 100% 4.52k/4.52k [00:00<00:00, 20.7MB/s]\n",
            "Applying attention optimization: xformers... done.\n",
            "Model loaded in 10.1s (calculate hash: 6.5s, load weights from disk: 0.2s, create model: 2.1s, apply weights to model: 0.9s, calculate empty prompt: 0.1s).\n",
            "reading metadata for /content/stable-diffusion-webui/models/Stable-diffusion/BraV4.safetensors: AssertionError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 74, in __init__\n",
            "    self.metadata = cache.cached_data_for_file('safetensors-metadata', \"checkpoint/\" + name, filename, read_metadata)\n",
            "  File \"/content/stable-diffusion-webui/modules/cache.py\", line 115, in cached_data_for_file\n",
            "    value = func()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 66, in read_metadata\n",
            "    metadata = read_metadata_from_safetensors(filename)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 269, in read_metadata_from_safetensors\n",
            "    assert metadata_len > 2 and json_start in (b'{\"', b\"{'\"), f\"{filename} is not a safetensors file\"\n",
            "AssertionError: /content/stable-diffusion-webui/models/Stable-diffusion/BraV4.safetensors is not a safetensors file\n",
            "\n",
            "reading metadata for /content/stable-diffusion-webui/models/Stable-diffusion/BraV4.safetensors: AssertionError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 74, in __init__\n",
            "    self.metadata = cache.cached_data_for_file('safetensors-metadata', \"checkpoint/\" + name, filename, read_metadata)\n",
            "  File \"/content/stable-diffusion-webui/modules/cache.py\", line 115, in cached_data_for_file\n",
            "    value = func()\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 66, in read_metadata\n",
            "    metadata = read_metadata_from_safetensors(filename)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 269, in read_metadata_from_safetensors\n",
            "    assert metadata_len > 2 and json_start in (b'{\"', b\"{'\"), f\"{filename} is not a safetensors file\"\n",
            "AssertionError: /content/stable-diffusion-webui/models/Stable-diffusion/BraV4.safetensors is not a safetensors file\n",
            "\n",
            "  0% 0/30 [00:00<?, ?it/s]\n",
            "  3% 1/30 [00:01<00:50,  1.73s/it]\n",
            "  7% 2/30 [00:01<00:23,  1.18it/s]\n",
            " 10% 3/30 [00:02<00:15,  1.75it/s]\n",
            " 13% 4/30 [00:02<00:11,  2.27it/s]\n",
            " 17% 5/30 [00:02<00:09,  2.64it/s]\n",
            " 20% 6/30 [00:02<00:07,  3.01it/s]\n",
            " 23% 7/30 [00:03<00:06,  3.31it/s]\n",
            " 27% 8/30 [00:03<00:06,  3.56it/s]\n",
            " 30% 9/30 [00:03<00:05,  3.65it/s]\n",
            " 33% 10/30 [00:03<00:05,  3.77it/s]\n",
            " 37% 11/30 [00:04<00:04,  3.87it/s]\n",
            " 40% 12/30 [00:04<00:04,  3.96it/s]\n",
            " 43% 13/30 [00:04<00:04,  3.97it/s]\n",
            " 47% 14/30 [00:04<00:04,  3.98it/s]\n",
            " 50% 15/30 [00:05<00:03,  4.00it/s]\n",
            " 53% 16/30 [00:05<00:03,  4.02it/s]\n",
            " 57% 17/30 [00:05<00:03,  3.97it/s]\n",
            " 60% 18/30 [00:05<00:03,  3.99it/s]\n",
            " 63% 19/30 [00:06<00:02,  3.95it/s]\n",
            " 67% 20/30 [00:06<00:02,  3.94it/s]\n",
            " 70% 21/30 [00:06<00:02,  3.92it/s]\n",
            " 73% 22/30 [00:06<00:02,  3.90it/s]\n",
            " 77% 23/30 [00:07<00:01,  3.89it/s]\n",
            " 80% 24/30 [00:07<00:01,  3.91it/s]\n",
            " 83% 25/30 [00:07<00:01,  3.89it/s]\n",
            " 87% 26/30 [00:07<00:01,  3.92it/s]\n",
            " 90% 27/30 [00:08<00:00,  3.90it/s]\n",
            " 93% 28/30 [00:08<00:00,  3.96it/s]\n",
            " 97% 29/30 [00:08<00:00,  4.00it/s]\n",
            "100% 30/30 [00:08<00:00,  3.35it/s]\n",
            "\n",
            "Total progress: 100% 30/30 [00:10<00:00,  2.91it/s]\n",
            "  0% 0/30 [00:00<?, ?it/s]\n",
            "  3% 1/30 [00:00<00:09,  3.19it/s]\n",
            "  7% 2/30 [00:00<00:07,  3.70it/s]\n",
            " 10% 3/30 [00:00<00:06,  3.89it/s]\n",
            " 13% 4/30 [00:01<00:06,  3.97it/s]\n",
            " 17% 5/30 [00:01<00:06,  3.90it/s]\n",
            " 20% 6/30 [00:01<00:06,  3.95it/s]\n",
            " 23% 7/30 [00:01<00:05,  3.97it/s]\n",
            " 27% 8/30 [00:02<00:05,  3.98it/s]\n",
            " 30% 9/30 [00:02<00:05,  3.94it/s]\n",
            " 33% 10/30 [00:02<00:05,  3.95it/s]\n",
            " 37% 11/30 [00:02<00:04,  3.99it/s]\n",
            " 40% 12/30 [00:03<00:04,  3.98it/s]\n",
            " 43% 13/30 [00:03<00:04,  3.95it/s]\n",
            " 47% 14/30 [00:03<00:04,  3.94it/s]\n",
            " 50% 15/30 [00:03<00:03,  3.98it/s]\n",
            " 53% 16/30 [00:04<00:03,  3.96it/s]\n",
            " 57% 17/30 [00:04<00:03,  3.95it/s]\n",
            " 60% 18/30 [00:04<00:03,  3.92it/s]\n",
            " 63% 19/30 [00:04<00:02,  3.95it/s]\n",
            " 67% 20/30 [00:05<00:02,  3.92it/s]\n",
            " 70% 21/30 [00:05<00:02,  3.88it/s]\n",
            " 73% 22/30 [00:05<00:02,  3.88it/s]\n",
            " 77% 23/30 [00:05<00:01,  3.95it/s]\n",
            " 80% 24/30 [00:06<00:01,  3.94it/s]\n",
            " 83% 25/30 [00:06<00:01,  3.91it/s]\n",
            " 87% 26/30 [00:06<00:01,  3.89it/s]\n",
            " 90% 27/30 [00:06<00:00,  3.92it/s]\n",
            " 93% 28/30 [00:07<00:00,  3.93it/s]\n",
            " 97% 29/30 [00:07<00:00,  3.93it/s]\n",
            "100% 30/30 [00:07<00:00,  3.92it/s]\n",
            "\n",
            "Total progress: 100% 30/30 [00:07<00:00,  3.82it/s]\n",
            "Reusing loaded model Basil_mix_fixed.safetensors [0ff127093f] to load BraV4.safetensors\n",
            "Calculating sha256 for /content/stable-diffusion-webui/models/Stable-diffusion/BraV4.safetensors: e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855\n",
            "Loading weights [e3b0c44298] from /content/stable-diffusion-webui/models/Stable-diffusion/BraV4.safetensors\n",
            "changing setting sd_model_checkpoint to BraV4.safetensors: SafetensorError\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stable-diffusion-webui/modules/options.py\", line 140, in set\n",
            "    option.onchange()\n",
            "  File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 13, in f\n",
            "    res = func(*args, **kwargs)\n",
            "  File \"/content/stable-diffusion-webui/modules/initialize_util.py\", line 170, in <lambda>\n",
            "    shared.opts.onchange(\"sd_model_checkpoint\", wrap_queued_call(lambda: sd_models.reload_model_weights()), call=False)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 741, in reload_model_weights\n",
            "    state_dict = get_checkpoint_state_dict(checkpoint_info, timer)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 315, in get_checkpoint_state_dict\n",
            "    res = read_state_dict(checkpoint_info.filename)\n",
            "  File \"/content/stable-diffusion-webui/modules/sd_models.py\", line 291, in read_state_dict\n",
            "    pl_sd = safetensors.torch.load_file(checkpoint_file, device=device)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/safetensors/torch.py\", line 259, in load_file\n",
            "    with safe_open(filename, framework=\"pt\", device=device) as f:\n",
            "safetensors_rust.SafetensorError: Error while deserializing header: HeaderTooSmall\n",
            "\n",
            "*** Error completing request\n",
            "*** Arguments: ('task(sqxnq6medq3tgcw)', '(anime,best quality, masterpiece, ultra highres:1.4), Beautiful Asian girl all nude by (japanese:1.3), (best_quality:1.6) 8k,1girl,(girl:1.6),girl,(sexy:1.7),(cute:1.5),(small breasts:1.2), blunt bangs,black hair,straight hair,(tiddler:1.6),(beautiful detailed eyes:1.1),(beautiful detailed face:1.2),(beautiful woman:1.4),(nsfw:1.6),(municipal pool:1.3),cloud,dynamic angle,wide shot,(group sex:1.1),(pussy:1.1),(ass:1.1),(gangbang:1.1),(have an orgy:1.3),(embarrassed:1.3),(blush:1.3),sweat,(microkini:1.3),(nipple slip:1.1),(smile:1.2),noon,sexy pose,play sex,sweat,(beautiful detailed crowd in crowds:1.1),(orgy:1),(buttocks:1.1),(photo session:1.1),cameraman', 'lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry,cat ears,gloves,clothes,ribon,sleeve clothes,umbrella,sagging breasts,(worst quality:2.0), (worst quality, low quality, lowres :1.4),wrinkles,poop,bad eyes,bad anus, bad pussy,fused anus, fused pussy,poorly drawn anus, poorly drawn pussy,meat curtain,extra legs,building,broken faces,', [], 30, 'Euler a', 1, 1, 7, 512, 768, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', '', '', [], <gradio.routes.Request object at 0x797cb0e37ca0>, 0, False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, 0, False) {}\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 57, in f\n",
            "        res = list(func(*args, **kwargs))\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 36, in f\n",
            "        res = func(*args, **kwargs)\n",
            "      File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 55, in txt2img\n",
            "        processed = processing.process_images(p)\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 732, in process_images\n",
            "        res = process_images_inner(p)\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 856, in process_images_inner\n",
            "        p.setup_conds()\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 1309, in setup_conds\n",
            "        super().setup_conds()\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 469, in setup_conds\n",
            "        self.uc = self.get_conds_with_caching(prompt_parser.get_learned_conditioning, negative_prompts, total_steps, [self.cached_uc], self.extra_network_data)\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 455, in get_conds_with_caching\n",
            "        cache[1] = function(shared.sd_model, required_prompts, steps, hires_steps, shared.opts.use_old_scheduling)\n",
            "      File \"/content/stable-diffusion-webui/modules/prompt_parser.py\", line 189, in get_learned_conditioning\n",
            "        conds = model.get_learned_conditioning(texts)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 665, in get_learned_conditioning\n",
            "        c = self.cond_stage_model.encode(c)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/encoders/modules.py\", line 135, in encode\n",
            "        return self(text)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/encoders/modules.py\", line 125, in forward\n",
            "        outputs = self.transformer(input_ids=tokens, output_hidden_states=self.layer == \"hidden\")\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\", line 822, in forward\n",
            "        return self.text_model(\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\", line 730, in forward\n",
            "        hidden_states = self.embeddings(input_ids=input_ids, position_ids=position_ids)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\", line 227, in forward\n",
            "        inputs_embeds = self.token_embedding(input_ids)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\", line 162, in forward\n",
            "        return F.embedding(\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2210, in embedding\n",
            "        return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
            "    RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)\n",
            "\n",
            "---\n",
            "*** Error completing request\n",
            "*** Arguments: ('task(r6yiy3m8bpkgmv0)', '(anime,best quality, masterpiece, ultra highres:1.4), Beautiful Asian girl all nude by (japanese:1.3), (best_quality:1.6) 8k,1girl,(girl:1.6),girl,(sexy:1.7),(cute:1.5),(small breasts:1.2), blunt bangs,black hair,straight hair,(tiddler:1.6),(beautiful detailed eyes:1.1),(beautiful detailed face:1.2),(beautiful woman:1.4),(nsfw:1.6),(municipal pool:1.3),cloud,dynamic angle,wide shot,(group sex:1.1),(pussy:1.1),(ass:1.1),(gangbang:1.1),(have an orgy:1.3),(embarrassed:1.3),(blush:1.3),sweat,(microkini:1.3),(nipple slip:1.1),(smile:1.2),noon,sexy pose,play sex,sweat,(beautiful detailed crowd in crowds:1.1),(orgy:1),(buttocks:1.1),(photo session:1.1),cameraman', 'lowres, bad anatomy, bad hands, text, error, missing fingers, extra digit, fewer digits, cropped, worst quality, low quality, normal quality, jpeg artifacts, signature, watermark, username, blurry,cat ears,gloves,clothes,ribon,sleeve clothes,umbrella,sagging breasts,(worst quality:2.0), (worst quality, low quality, lowres :1.4),wrinkles,poop,bad eyes,bad anus, bad pussy,fused anus, fused pussy,poorly drawn anus, poorly drawn pussy,meat curtain,extra legs,building,broken faces,', [], 30, 'Euler a', 1, 1, 7, 512, 768, False, 0.7, 2, 'Latent', 0, 0, 0, 'Use same checkpoint', 'Use same sampler', '', '', [], <gradio.routes.Request object at 0x797cb0e92fe0>, 0, False, '', 0.8, -1, False, -1, 0, 0, 0, False, False, 'positive', 'comma', 0, False, False, '', 1, '', [], 0, '', [], 0, '', [], True, False, False, False, 0, False) {}\n",
            "    Traceback (most recent call last):\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 57, in f\n",
            "        res = list(func(*args, **kwargs))\n",
            "      File \"/content/stable-diffusion-webui/modules/call_queue.py\", line 36, in f\n",
            "        res = func(*args, **kwargs)\n",
            "      File \"/content/stable-diffusion-webui/modules/txt2img.py\", line 55, in txt2img\n",
            "        processed = processing.process_images(p)\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 732, in process_images\n",
            "        res = process_images_inner(p)\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 856, in process_images_inner\n",
            "        p.setup_conds()\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 1309, in setup_conds\n",
            "        super().setup_conds()\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 469, in setup_conds\n",
            "        self.uc = self.get_conds_with_caching(prompt_parser.get_learned_conditioning, negative_prompts, total_steps, [self.cached_uc], self.extra_network_data)\n",
            "      File \"/content/stable-diffusion-webui/modules/processing.py\", line 455, in get_conds_with_caching\n",
            "        cache[1] = function(shared.sd_model, required_prompts, steps, hires_steps, shared.opts.use_old_scheduling)\n",
            "      File \"/content/stable-diffusion-webui/modules/prompt_parser.py\", line 189, in get_learned_conditioning\n",
            "        conds = model.get_learned_conditioning(texts)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/models/diffusion/ddpm.py\", line 665, in get_learned_conditioning\n",
            "        c = self.cond_stage_model.encode(c)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/encoders/modules.py\", line 135, in encode\n",
            "        return self(text)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "      File \"/content/stable-diffusion-webui/repositories/stable-diffusion-stability-ai/ldm/modules/encoders/modules.py\", line 125, in forward\n",
            "        outputs = self.transformer(input_ids=tokens, output_hidden_states=self.layer == \"hidden\")\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\", line 822, in forward\n",
            "        return self.text_model(\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\", line 730, in forward\n",
            "        hidden_states = self.embeddings(input_ids=input_ids, position_ids=position_ids)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/transformers/models/clip/modeling_clip.py\", line 227, in forward\n",
            "        inputs_embeds = self.token_embedding(input_ids)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 1501, in _call_impl\n",
            "        return forward_call(*args, **kwargs)\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/sparse.py\", line 162, in forward\n",
            "        return F.embedding(\n",
            "      File \"/usr/local/lib/python3.10/dist-packages/torch/nn/functional.py\", line 2210, in embedding\n",
            "        return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
            "    RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument index in method wrapper_CUDA__index_select)\n",
            "\n",
            "---\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "authorship_tag": "ABX9TyNumf0NQhyPmwAzZZju1sNS",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}